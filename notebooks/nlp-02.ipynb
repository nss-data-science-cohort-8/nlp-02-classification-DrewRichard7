{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train a text classification model to identify the issue type based on the consumer complaint narrative.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = pd.read_csv(\"../data/complaints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thought process:\n",
    "\n",
    "1. clean data\n",
    "2. tokenize complaints\n",
    "3. define predictor and target\n",
    "4. train_test_split\n",
    "5. vectorize text\n",
    "6. sentiment analysis\n",
    "7. train model\n",
    "8. validation of training \n",
    "9. test model\n",
    "10. Cross validation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Head---\n",
      "                         Consumer complaint narrative  \\\n",
      "0  My name is XXXX XXXX this complaint is not mad...   \n",
      "1  I searched on XXXX for XXXXXXXX XXXX  and was ...   \n",
      "2  I have a particular account that is stating th...   \n",
      "3  I have not supplied proof under the doctrine o...   \n",
      "4  Hello i'm writing regarding account on my cred...   \n",
      "\n",
      "                                  Issue  \n",
      "0  Incorrect information on your report  \n",
      "1                         Fraud or scam  \n",
      "2  Incorrect information on your report  \n",
      "3     Attempts to collect debt not owed  \n",
      "4  Incorrect information on your report  \n",
      "\n",
      "\n",
      "---Tail---\n",
      "                              Consumer complaint narrative  \\\n",
      "353427         Collections account I have no knowledge of   \n",
      "353428  Dear CFPB Team, The reason for my complaint is...   \n",
      "353429  FRCA violations : Failing to Follow Debt Dispu...   \n",
      "353430  My Father, a XXXX XXXX  acquired an HECM rever...   \n",
      "353431  I have tried to contact cash app about a fraud...   \n",
      "\n",
      "                                    Issue  \n",
      "353427  Attempts to collect debt not owed  \n",
      "353428  Attempts to collect debt not owed  \n",
      "353429  Attempts to collect debt not owed  \n",
      "353430         Struggling to pay mortgage  \n",
      "353431                      Fraud or scam  \n",
      "\n",
      "\n",
      "---Describe---\n",
      "                              Consumer complaint narrative  \\\n",
      "count                                              353432   \n",
      "unique                                             353228   \n",
      "top     My information was used to obtain an apartment...   \n",
      "freq                                                    3   \n",
      "\n",
      "                                       Issue  \n",
      "count                                 353432  \n",
      "unique                                     5  \n",
      "top     Incorrect information on your report  \n",
      "freq                                  229305  \n",
      "\n",
      "---Shape--- \n",
      "(353432, 2)\n",
      "\n",
      "\n",
      "---NaNs--- \n",
      "Consumer complaint narrative    0\n",
      "Issue                           0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "---Issue Type value_counts--- \n",
      "Issue\n",
      "Incorrect information on your report    229305\n",
      "Attempts to collect debt not owed        73163\n",
      "Communication tactics                    21243\n",
      "Struggling to pay mortgage               17374\n",
      "Fraud or scam                            12347\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n---Head---\\n {complaints.head()}\\n\")\n",
    "print(f\"\\n---Tail---\\n {complaints.tail()}\\n\")\n",
    "print(f\"\\n---Describe---\\n {complaints.describe()}\\n\")\n",
    "print(f\"---Shape--- \\n{complaints.shape}\\n\")\n",
    "print(f\"\\n---NaNs--- \\n{complaints.isna().sum()}\\n\")\n",
    "print(f\"\\n---Issue Type value_counts--- \\n{complaints['Issue'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m complaint \u001b[38;5;129;01min\u001b[39;00m complaints[\u001b[33m'\u001b[39m\u001b[33mConsumer complaint narrative\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m      3\u001b[39m     tokens = word_tokenize(complaint)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     tokens = [token.lower() \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstopwords\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43menglish\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[32m      5\u001b[39m     tokens.append(tokens)\n\u001b[32m      7\u001b[39m display(tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/nss/nss_projects/nlp-02-classification-DrewRichard7/.venv/lib/python3.12/site-packages/nltk/corpus/reader/wordlist.py:20\u001b[39m, in \u001b[36mWordListCorpusReader.words\u001b[39m\u001b[34m(self, fileids, ignore_lines_startswith)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids=\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         line\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28mself\u001b[39m.raw(fileids))\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line.startswith(ignore_lines_startswith)\n\u001b[32m     23\u001b[39m     ]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for complaint in complaints['Consumer complaint narrative']:\n",
    "    tokens = word_tokenize(complaint)\n",
    "    tokens = [token.lower() for token in tokens if token not in stopwords.words('english')]\n",
    "    tokens.append(tokens)\n",
    "\n",
    "display(tokens)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
